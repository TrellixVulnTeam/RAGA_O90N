{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder Notebook\n",
    "Generative Algorithm that has been trained using FIRST Radio Sources. Makes use of the FRDEEP dataset of FIRST Radio Sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from MiraBest import MiraBest\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports the images from the FRDEEP, we make use of the FIRST radio sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FRDEEP import FRDEEPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_first():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])\n",
    "    \n",
    "    trainset = FRDEEPF(root='./FIRST_data', train=True, download=True, transform=transform)  \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=len(trainset))\n",
    "    \n",
    "    testset = FRDEEPF(root='./FIRST_data', train=False, download=True, transform=transform) \n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=True, num_workers=2,batch_size = len(trainset))\n",
    "    \n",
    "    classes = ('FRI', 'FRII')\n",
    "    \n",
    "    array_train= next(iter(trainloader))[0].numpy() # Training Datasets is loaded in numpy array\n",
    "    \n",
    "    array_label= next(iter(trainloader))[1].numpy() # Training Datasets labels is loaded in seperate numpy array\n",
    "    \n",
    "    augmented_data=np.zeros((19800,1,100,100))\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for j in range(0,550):\n",
    "        image_object=Image.fromarray(array_train[j,0,:,:])\n",
    "        for i in range(0,36):\n",
    "            rotated=image_object.rotate(i*10)\n",
    "            imgarr = np.array(rotated)\n",
    "            temp_img_array=imgarr[25:125,25:125]\n",
    "            augmented_data[count,0,:,:]=temp_img_array\n",
    "            count+=1\n",
    "           \n",
    "    augmented_data=(augmented_data-np.min(augmented_data))/(np.max(augmented_data)-np.min(augmented_data))\n",
    "    \n",
    "    X=augmented_data\n",
    "    \n",
    "    X_random_mix=np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X);\n",
    "    \n",
    "    array_test = next(iter(testloader))[0].numpy()\n",
    "    \n",
    "    augmented_data_test=np.zeros((50,1,100,100))\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for j in range(0,50):\n",
    "        image_object=Image.fromarray(array_test[j,0,:,:])\n",
    "        for i in range(0,1):\n",
    "            rotated=image_object.rotate(i*10)\n",
    "            imgarr = np.array(rotated)\n",
    "            temp_img_array=imgarr[25:125,25:125]\n",
    "            augmented_data[count,0,:,:]=temp_img_array\n",
    "            count+=1\n",
    "           \n",
    "    augmented_data_test=(augmented_data_test-np.min(augmented_data_test))/(np.max(augmented_data_test)-np.min(augmented_data_test))\n",
    "    \n",
    "    X_test=augmented_data_test\n",
    "    \n",
    "    X_random_mix_test=np.take(X,np.random.permutation(X_test.shape[0]),axis=0,out=X_test);\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_random_mix,X_random_mix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder Neural Network \n",
    "The Variational Auto Encoder consists of two neural network: i. An encoder and ii.a decoder.  \n",
    "- The Encoder\\\n",
    "The enncoder consists of 5 layers and an input layer. The 100 by 100 pizels are reshaped to 10000 input features that are then reduced to 4096 in the first connected layer, then to 2048 features, then to 1024 features, to 512 features, 256 features and finally to the final 2 dimensional latent space z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, h_dim3, h_dim4, h_dim5, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1) #x_dim=10000 to h_dim1=4096 \n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2) #h_dim1=4096 to h_dim2=2048\n",
    "        self.fc3 = nn.Linear(h_dim2, h_dim3) #h_dim2=2048 to h_dim3=1024\n",
    "        self.fc4 = nn.Linear(h_dim3, h_dim4) #h_dim3=1024 to h_dim4=512\n",
    "        self.fc5 = nn.Linear(h_dim4, h_dim5) #h_dim4=512 to h_dim5=256\n",
    "        self.fc61 = nn.Linear(h_dim5, z_dim) #h_dim5=256 to z_dim=2\n",
    "        self.fc62 = nn.Linear(h_dim5, z_dim) #h_dim5=256 to z_dim=2\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        # decoder part\n",
    "        self.fc7 = nn.Linear(z_dim, h_dim5) #z_dim=2 to h_dim5=256\n",
    "        self.fc8 = nn.Linear(h_dim5, h_dim4) #h_dim5=256 to h_dim4=512\n",
    "        self.fc9 = nn.Linear(h_dim4, h_dim3) #h_dim4=512 to h_dim3=1024\n",
    "        self.fc10 = nn.Linear(h_dim3, h_dim2) #h_dim3=1024 to h_dim2=2048\n",
    "        self.fc11 = nn.Linear(h_dim2, h_dim1) #h_dim2=2048 to h_dim1=4096\n",
    "        self.fc12 = nn.Linear(h_dim1, x_dim)  #h_dim1=4096 to x_dim=10000\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        \n",
    "        slope_param = 0.0001\n",
    "        \n",
    "        h = self.softplus(self.fc1(x))\n",
    "        h = F.leaky_relu(self.fc2(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc3(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc4(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc5(h),slope_param)\n",
    "        return self.fc61(h), self.fc62(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        slope_param = 0.0001\n",
    "        h = F.leaky_relu(self.fc7(z),slope_param)\n",
    "        h = F.leaky_relu(self.fc8(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc9(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc10(h),slope_param)\n",
    "        h = F.leaky_relu(self.fc11(h),slope_param)\n",
    "        return F.sigmoid(self.fc12(h)) # Try to see what happens when we put a Softplus Here\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 10000))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "vae = VAE(x_dim=10000, h_dim1= 4096, h_dim2=2048, h_dim3=1024, h_dim4=512, h_dim5=256, z_dim=2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adagrad(vae.parameters(), lr=0.3e-3)\n",
    "\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 10000), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda-python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "X,X_test= dataloader_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1, 100, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0   \n",
    "    data=torch.zeros(100, 1, 100, 100).cpu\n",
    "    epoch_loss = 0\n",
    "    for j in range(0,198):\n",
    "        data = torch.from_numpy(X[j*100:(j+1)*100,:,:])\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data.float())\n",
    "        loss = loss_function(recon_batch.float(), data.float(), mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        epoch_loss+=loss.item() / len(data)\n",
    "        \n",
    "        #Testing Part:\n",
    "        data_test = torch.from_numpy(X_test)\n",
    "        data_test = data_test.cuda()\n",
    "        recon_batch_test,mu_test,log_var_test = vae(data_test.float())\n",
    "        test_loss = loss_function(recon_batch_testfloat(), data_test, mu_test, log_var_test).item()\n",
    "        \n",
    "        \n",
    "    print(\"Training Epoch:\"+str(epoch)+' Training Loss: '+str(epoch_loss/198.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "reduce failed to synchronize: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5186fabbb9fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-c0d2f8fb9ddb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e1877acd74bc>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(recon_x, x, mu, log_var)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# return reconstruction error + KL divergence losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mBCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mKLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mKLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda-python-3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2051\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: reduce failed to synchronize: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the images from the latent space z, sample range between $-4.0 \\leqslant z_1 \\leqslant 4.0$ and $-4.0 \\leqslant z_2 \\leqslant 4.0$. Image are sampled at steps of 0.2 in both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1600, 2).cuda()\n",
    "    count_x=-4.0\n",
    "    count_y=-4.0\n",
    "    x=0\n",
    "    y=0\n",
    "    for i in range (0,40):\n",
    "        for j in range (0,40):\n",
    "            z[x,0]=count_x\n",
    "            z[x,1]=count_y\n",
    "            x=x+1\n",
    "            count_y=count_y+0.2\n",
    "        y=y+1\n",
    "        count_x=count_x+0.2\n",
    "        count_y=-4.0\n",
    "        \n",
    "    sample = vae.decoder(z).cuda()\n",
    "    \n",
    "    save_image(sample.view(1600, 1, 100, 100), 'sample_z_space_' +str(epoch)+'.png',nrow=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(100, 2).cuda()    \n",
    "    sample = vae.decoder(z).cuda()\n",
    "    save_image(sample.view(100, 1, 100, 100), 'sample_random_' +str(epoch)+'.png',nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
