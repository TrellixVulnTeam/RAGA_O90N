{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bga import BGA\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam,Adagrad\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image \n",
    "\n",
    "from MiraBest import MiraBest\n",
    "from FRDEEP import FRDEEPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "\n",
    "smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_first():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "    trainset = MiraBest(root='./FIRST_data', train=True, download=True, transform=transform)  \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=len(trainset))\n",
    "    \n",
    "    classes = ('FRI', 'FRII') #First class if FR1 and second class is FR2\n",
    "    \n",
    "    array_train= next(iter(trainloader))[0].numpy() # Training Datasets is loaded in numpy array\n",
    "    array_label= next(iter(trainloader))[1].numpy()\n",
    "    \n",
    "    augmented_data=np.zeros((len(array_train)*36,1,100,100))\n",
    "    \n",
    "    augmented_data_label = np.zeros((len(array_train)*36,1))\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for j in range(0,len(array_train)):\n",
    "        image_object=Image.fromarray(array_train[j,0,:,:])\n",
    "        for i in range(0,36):\n",
    "            rotated=image_object.rotate(i*10)\n",
    "            imgarr = np.array(rotated)\n",
    "            temp_img_array=imgarr[25:125,25:125]\n",
    "            augmented_data[count,0,:,:]=temp_img_array\n",
    "            augmented_data_label[count,:]=array_label[j]\n",
    "            count+=1\n",
    "    augmented_data=(augmented_data-np.min(augmented_data))/(np.max(augmented_data)-np.min(augmented_data))\n",
    "    \n",
    "    X=augmented_data\n",
    "    Y=augmented_data_label\n",
    "    \n",
    "    X_random_mix=np.take(X,np.random.RandomState(seed=42).permutation(X.shape[0]),axis=0,out=X)\n",
    "    Y_random_mix=np.take(Y,np.random.RandomState(seed=42).permutation(Y.shape[0]),axis=0,out=Y)\n",
    "    \n",
    "    tensor_x = torch.stack([torch.Tensor(i) for i in X_random_mix])\n",
    "    tensor_y = torch.stack([torch.Tensor(i) for i in Y_random_mix])\n",
    "    \n",
    "    first_augmented_dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y)\n",
    "    \n",
    "    first_dataloader = torch.utils.data.DataLoader(first_augmented_dataset,batch_size=100, shuffle=True) # create your dataloader\n",
    "    \n",
    "    #--------------------------------------Add Section for Test data------------------------------------\n",
    "    \n",
    "    # Cropping of the Testing Images to 100 by 100 pixels\n",
    "    \n",
    "    \n",
    "    testset = MiraBest(root='./FIRST_data', train=False, download=True, transform=transform) \n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=True, num_workers=2, batch_size=len(testset))\n",
    "\n",
    "    array_test= next(iter(testloader))[0].numpy()\n",
    "    \n",
    "    test_labels = next(iter(testloader))[1].numpy()\n",
    "    \n",
    "    test_data_reduced=np.zeros((len(array_test),1,100,100))\n",
    "    test_data_label = np.zeros((len(array_test),1))\n",
    "    \n",
    "    for k in range (0,len(array_test)):\n",
    "        test_data_reduced[k][0][:][:] = array_test[k][0][25:125,25:125]\n",
    "        test_data_label[k,:]=test_labels[k]\n",
    "    \n",
    "    test_data_reduced=(test_data_reduced-np.min(test_data_reduced))/(np.max(test_data_reduced)-np.min(test_data_reduced))\n",
    "    \n",
    "    \n",
    "    \n",
    "    tensor_test = torch.stack([torch.Tensor(i) for i in test_data_reduced])\n",
    "    tensor_test_label = torch.stack([torch.Tensor(i) for i in test_data_label])\n",
    "    \n",
    "    first_augmented_dataset_test = torch.utils.data.TensorDataset(tensor_test,tensor_test_label) # create your datset\n",
    "    \n",
    "    first_dataloader_test = torch.utils.data.DataLoader(first_augmented_dataset_test,batch_size=50, shuffle=True) # create your dataloader\n",
    "    \n",
    "    return first_dataloader,first_dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Encoder Z Network- Encodes the images to the z latent space --------------------------\n",
    "class EncoderZ(nn.Module):\n",
    "    #def __init__(self, z_dim, hidden_dim):\n",
    "    def __init__(self, x_dim, y_dim, h_dim_enco_1, h_dim_enco_2, z_dim):\n",
    "        super(EncoderZ, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_dim+y_dim, h_dim_enco_1) # x_dim=10000 + y_dim=2 to h_dim1=4096 \n",
    "        self.fc2 = nn.Linear(h_dim_enco_1, h_dim_enco_2) #h_dim1=4096 to h_dim2=2048\n",
    "        self.fc31 = nn.Linear(h_dim_enco_2, z_dim) #h_dim5=256 to z_dim=2\n",
    "        self.fc32 = nn.Linear(h_dim_enco_2, z_dim) #h_dim5=256 to z_dim=2\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x_y_2):\n",
    "        [x,y]=x_y_2\n",
    "        \n",
    "        x = x.reshape(-1, 10000) \n",
    "        y = y.reshape(-1, 2) \n",
    "        \n",
    "        x_y_1 = torch.cat((x,y), dim=1) \n",
    "        x_y_1 = x_y_1.view(x_y_1.size(0), -1)\n",
    "        \n",
    "        slope_param=0.0001\n",
    "        \n",
    "        # then compute the hidden units\n",
    "        # We use fully connected layers\n",
    "        hidden = self.softplus(self.fc1(x_y_1))\n",
    "        \n",
    "        \n",
    "       # hidden = F.leaky_relu(self.fc1(x),slope_param)\n",
    "        hidden = F.leaky_relu(self.fc2(hidden),slope_param)\n",
    "        \n",
    "        z_loc = self.fc31(hidden)\n",
    "        z_scale = torch.exp(self.fc32(hidden)) # mu, log_var\n",
    "        \n",
    "        \n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Encoder Z Network- Encodes the images to the z latent space --------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim, h_dim_deco_1, h_dim_deco_2, z_dim): #Change this part of the code that we have a 2-layer MLP\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc4 = nn.Linear(z_dim+y_dim, h_dim_deco_1) #z_dim=2 to h_dim5=256\n",
    "        self.fc5 = nn.Linear(h_dim_deco_1, h_dim_deco_2) #h_dim5=256 to h_dim4=512\n",
    "        self.fc6 = nn.Linear(h_dim_deco_2, x_dim)  #h_dim1=4096 to x_dim=10000\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,z_y_2):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        \n",
    "        [z,y]=z_y_2\n",
    "        \n",
    "        z = z.reshape(-1, 16) #@David Change this to reshape if something fucks up\n",
    "        y = y.reshape(-1, 2)\n",
    "        z_y_1 = torch.cat((z,y), dim=1)\n",
    "        z_y_1 = z_y_1.view(z_y_1.size(0), -1)\n",
    "        \n",
    "        slope_param=0.0001\n",
    "        hidden = F.leaky_relu(self.fc4(z_y_1),slope_param)\n",
    "        hidden = F.leaky_relu(self.fc5(hidden),slope_param)\n",
    "        loc_img = self.sigmoid(self.fc6(hidden))\n",
    "        return loc_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, x_dim, y_dim, h_dim_enco_1, h_dim_enco_2, h_dim_deco_1, h_dim_deco_2, z_dim, use_cuda): #we should here pass the different network arichtectures layer architecture\n",
    "        super(VAE, self).__init__()\n",
    "    \n",
    "        # create the encoder and decoder networks\n",
    "        # a split in the final layer's size is used for multiple outputs\n",
    "        # and potentially applying separate activation functions on them\n",
    "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
    "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
    "              \n",
    "        self.encoder_z = EncoderZ(x_dim, y_dim, h_dim_enco_1, h_dim_enco_2, z_dim)\n",
    "        \n",
    "        self.decoder = Decoder(x_dim, y_dim, h_dim_deco_1, h_dim_deco_2, z_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "            \n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "        self.output_size = y_dim\n",
    "        \n",
    "        \n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, xs, ys):\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"ss_vae\", self)\n",
    "        batch_size = xs.size(0)\n",
    "\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            # sample the handwriting style from the constant prior distribution\n",
    "            prior_loc = xs.new_zeros([batch_size, self.z_dim])\n",
    "            prior_scale = xs.new_ones([batch_size, self.z_dim])\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "            alpha_prior = xs.new_ones([batch_size, self.output_size]) / (1.0 * self.output_size)\n",
    "            ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha_prior), obs=ys)\n",
    "            \n",
    "            # finally, score the image (x) using the handwriting style (z) and\n",
    "            # the class label y (which digit to write) against the\n",
    "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
    "            # where `decoder` is a neural network\n",
    "            loc = self.decoder.forward([zs, ys])\n",
    "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
    "            \n",
    "    def guide(self, xs, ys):\n",
    "        with pyro.plate(\"data\"):\n",
    "           # if the class label (the digit) is not supervised, sample\n",
    "           # (and score) the digit with the variational distribution\n",
    "           # q(y|x) = categorical(alpha(x))\n",
    "           \n",
    "            #-------------------REMOVED THIS PART FOR THE CLASSIFIER ASSUME ALL DATA ARE LABELLED---------\n",
    "\n",
    "           # sample (and score) the latent handwriting-style with the variational\n",
    "           # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "           loc, scale = self.encoder_z.forward([xs, ys])\n",
    "           pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, xs, ys):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder_z.forward([xs,ys])\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder.forward([zs,ys])\n",
    "        \n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=True):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, y in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        labels_y = torch.tensor(np.zeros((y.shape[0],2)))\n",
    "        y_2=torch.Tensor.cpu(y.reshape(1,y.size()[0])[0]).numpy().astype(int)  \n",
    "        labels_y=np.eye(2)[y_2]\n",
    "        labels_y = torch.from_numpy(labels_y)      \n",
    "                 \n",
    "        epoch_loss += svi.step(x.reshape(-1,10000),labels_y.cuda().float())\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the mini batch logic is handled by the data loader, we should duplicate the same logic of the data loader with the FIRST Database. The core of the training loop is svi.step(x). This is the data entry point. It should be noted that we have to change the looping structure to that of the mini batch structure that is used for the FIRST database.\n",
    "\n",
    "# To do evaluate part afterwards\n",
    "\n",
    "def evaluate(svi, test_loader, use_cuda=True):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x,y in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x) #Data entry point <---------------------------------Data Entry Point\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sVAE(arr):\n",
    "    \n",
    "    X_DIM = 10000\n",
    "    Y_DIM = 2\n",
    "    Z_DIM=16\n",
    "    ALPHA_ENCO = int(\"\".join(str(i) for i in arr[0:10]),2)\n",
    "    BETA_ENCO = int(\"\".join(str(i) for i in arr[10:18]),2)\n",
    "\n",
    "    \n",
    "    H_DIM_ENCO_1 = ALPHA_ENCO + BETA_ENCO\n",
    "    \n",
    "    H_DIM_ENCO_2 = ALPHA_ENCO\n",
    "    \n",
    "    H_DIM_DECO_1 = ALPHA_ENCO\n",
    "    \n",
    "    H_DIM_DECO_2 = ALPHA_ENCO + BETA_ENCO\n",
    "       \n",
    "    print(str(H_DIM_ENCO_1))\n",
    "    print(str(H_DIM_ENCO_2))\n",
    "    print(str(H_DIM_DECO_1))\n",
    "    print(str(H_DIM_DECO_2))\n",
    "    print('-----------')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Run options\n",
    "    LEARNING_RATE = 1.0e-3\n",
    "    USE_CUDA = True\n",
    "\n",
    "    # Run only for a single iteration for testing\n",
    "    NUM_EPOCHS = 501\n",
    "    TEST_FREQUENCY = 5\n",
    "\n",
    "    train_loader,test_loader = dataloader_first()\n",
    "    # clear param store\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    # setup the VAE\n",
    "    vae = VAE(x_dim=X_DIM, y_dim=Y_DIM, h_dim_enco_1=H_DIM_ENCO_1, h_dim_enco_2=H_DIM_ENCO_2, h_dim_deco_1=H_DIM_DECO_1, h_dim_deco_2=H_DIM_DECO_1, z_dim=Z_DIM, use_cuda=USE_CUDA)\n",
    "\n",
    "    # setup the optimizer\n",
    "    adagrad_params = {\"lr\": 0.00003}\n",
    "    optimizer = Adagrad(adagrad_params)\n",
    "\n",
    "\n",
    "    svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "    train_elbo = []\n",
    "    test_elbo = []\n",
    "    # training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_epoch_loss_train = train(svi, train_loader,  use_cuda=USE_CUDA)\n",
    "    \n",
    "        train_elbo.append(-total_epoch_loss_train)\n",
    "        \n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "    \n",
    "        if epoch==500:\n",
    "        # --------------------------Do testing for each epoch here--------------------------------\n",
    "        # initialize loss accumulator\n",
    "            test_loss = 0.\n",
    "        # compute the loss over the entire test set\n",
    "            for x_test,y_test in test_loader:\n",
    " \n",
    "                x_test = x_test.cuda()\n",
    "                y_test = y_test.cuda()\n",
    "                # compute ELBO estimate and accumulate loss\n",
    "                labels_y_test = torch.tensor(np.zeros((y_test.shape[0],2)))\n",
    "                y_test_2=torch.Tensor.cpu(y_test.reshape(1,y_test.size()[0])[0]).numpy().astype(int)  \n",
    "                labels_y_test=np.eye(2)[y_test_2]\n",
    "                labels_y_test = torch.from_numpy(labels_y_test)\n",
    "        \n",
    "                test_loss += svi.evaluate_loss(x_test.reshape(-1,10000),labels_y_test.cuda().float()) #Data entry point <---------------------------------Data Entry Point\n",
    "            \n",
    "            normalizer_test = len(test_loader.dataset)\n",
    "            total_epoch_loss_test = test_loss / normalizer_test\n",
    "            print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_test))\n",
    "            return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- RUNNING PART --------------------------            \n",
    "\n",
    "#print(main_sVAE(X_DIM=10000,Y_DIM=2,H_DIM_ENCO_1=4096,H_DIM_ENCO_2=1024,H_DIM_DECO_1=1024,H_DIM_DECO_2=4096,Z_DIM=16))\n",
    "\n",
    "num_pop = 8\n",
    "\n",
    "problem_dimentions = 18\n",
    "\n",
    "test = BGA(pop_shape=(num_pop, problem_dimentions), method=main_sVAE, p_c=0.9, p_m=0.9, max_round = 20, early_stop_rounds=None, verbose = None, maximum=False)\n",
    "best_solution, best_fitness = test.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
