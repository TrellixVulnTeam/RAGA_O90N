{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import HMT\n",
    "from plots import *\n",
    "from FRDEEP import FRDEEPN, FRDEEPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size    = 110    # number of samples for validation\n",
    "batch_size    = 16     # number of samples per mini-batch\n",
    "num_classes   = 2      # The number of output classes. FRI/FRII\n",
    "lr0           = torch.tensor(1e-2)  # The speed of convergence\n",
    "momentum      = torch.tensor(9e-1)  # momentum for optimizer\n",
    "num_batches   = 55     # multiplies up the total samples to ~30k like in paper\n",
    "class_weights = torch.FloatTensor([0.6,0.4]) # for training\n",
    "random_seed   = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "#    transforms.CenterCrop(28),\n",
    "    transforms.RandomRotation(0.,360.),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))])\n",
    "\n",
    "train_data = FRDEEPF('first', train=True, download=True, transform=transform)\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = valid_size\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = FRDEEPF('first', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMT()\n",
    "learning_rate = lr0\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=1e-6)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 150, 150]             732\n",
      "       BatchNorm2d-2          [-1, 6, 150, 150]              12\n",
      "         MaxPool2d-3            [-1, 6, 75, 75]               0\n",
      "            Conv2d-4           [-1, 16, 75, 75]           2,416\n",
      "       BatchNorm2d-5           [-1, 16, 75, 75]              32\n",
      "         MaxPool2d-6           [-1, 16, 25, 25]               0\n",
      "            Conv2d-7           [-1, 24, 25, 25]           3,480\n",
      "       BatchNorm2d-8           [-1, 24, 25, 25]              48\n",
      "            Conv2d-9           [-1, 24, 25, 25]           5,208\n",
      "      BatchNorm2d-10           [-1, 24, 25, 25]              48\n",
      "           Conv2d-11           [-1, 16, 25, 25]           3,472\n",
      "      BatchNorm2d-12           [-1, 16, 25, 25]              32\n",
      "        MaxPool2d-13             [-1, 16, 5, 5]               0\n",
      "          Flatten-14                  [-1, 400]               0\n",
      "           Linear-15                  [-1, 256]         102,656\n",
      "          Dropout-16                  [-1, 256]               0\n",
      "           Linear-17                  [-1, 256]          65,792\n",
      "          Dropout-18                  [-1, 256]               0\n",
      "           Linear-19                  [-1, 256]          65,792\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                    [-1, 2]             514\n",
      "              HMT-22                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 250,234\n",
      "Trainable params: 250,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 4.40\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 4.00\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(250234), tensor(250234))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.034753382205963135, Train Accuracy: 0.9989448051948052\n",
      "Epoch: 0, Loss: 2.399550221678529, Validation Accuracy: 0.8181122442344566\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 92 %\n",
      "#####################################################################\n",
      "Epoch: 1, Loss: 8.701899787411094e-06, Train Accuracy: 0.9996753246753247\n",
      "Epoch: 1, Loss: 3.238989293479795, Validation Accuracy: 0.8280612236493594\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 92 %\n",
      "#####################################################################\n",
      "Epoch: 2, Loss: 0.0010835780994966626, Train Accuracy: 0.9998376623376624\n",
      "Epoch: 2, Loss: 3.044120230549578, Validation Accuracy: 0.845709646677042\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 92 %\n",
      "#####################################################################\n",
      "Epoch: 3, Loss: 2.0778017642442137e-05, Train Accuracy: 1.0\n",
      "Epoch: 3, Loss: 3.2426717968448737, Validation Accuracy: 0.8455705003304915\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 92 %\n",
      "#####################################################################\n",
      "Epoch: 4, Loss: 0.0, Train Accuracy: 0.9999594155844156\n",
      "Epoch: 4, Loss: 3.6118359040277954, Validation Accuracy: 0.8179499067269362\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 96 %\n",
      "#####################################################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2f7f47ed6184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda-python-3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda-python-3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "epoch_trainaccs, epoch_validaccs = [], []\n",
    "\n",
    "classes = ('FRI', 'FRII')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_accs=[]; acc = 0\n",
    "    for iter in range(num_batches):\n",
    "        for batch, (x_train, y_train) in enumerate(train_loader):\n",
    "            model.zero_grad()\n",
    "            pred = model(x_train)\n",
    "            loss = criterion(pred,y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = (pred.argmax(dim=-1) == y_train).to(torch.float32).mean()\n",
    "            train_accs.append(acc.mean().item())\n",
    "\n",
    "    print('Epoch: {}, Loss: {}, Train Accuracy: {}'.format(epoch, loss, np.mean(train_accs)))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_losses, valid_accs = [], []; acc = 0\n",
    "        for iter in range(num_batches):\n",
    "            for i, (x_val, y_val) in enumerate(valid_loader):\n",
    "                valid_pred = model(x_val)\n",
    "                loss = criterion(valid_pred,y_val)\n",
    "                acc = (valid_pred.argmax(dim=-1) == y_val).to(torch.float32).mean()\n",
    "                valid_losses.append(loss.item())\n",
    "                valid_accs.append(acc.mean().item())\n",
    "\n",
    "    print('Epoch: {}, Loss: {}, Validation Accuracy: {}'.format(epoch, np.mean(valid_losses), np.mean(valid_accs)))\n",
    "    epoch_trainaccs.append(np.mean(train_accs))\n",
    "    epoch_validaccs.append(np.mean(valid_accs))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    class_correct = list(0. for i in range(2))\n",
    "    class_total = list(0. for i in range(2))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    \n",
    "    print('#####################################################################')    \n",
    "    torch.save(model,'model_1.out')\n",
    "print(\"Final validation error: \",100.*(1 - epoch_validaccs[-1]))\n",
    "\n",
    "#plot_error(epoch_trainaccs, epoch_validaccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
