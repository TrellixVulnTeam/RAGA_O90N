{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised VAE for FRI and FRII Source Generation\n",
    "\n",
    "## Introduction\n",
    "### The Variational Auto Encoder\n",
    "Auto Encoders are neural networks that consist of two networks an Encoder that reduced the higher dimensional data $x^{(i)}$ where $x^{(i)} \\in R^{D}$ to a lower dimensional space $y^{(i)}$ where $y^{(i)} \\in R^{d}$ and where $d < D$. The decoder takes the reduced vector $y^{(i)}$ back to higher dimensional space $\\hat{x}^{(i)}$ where $\\hat{x}^{(i)} \\in R^{D}$. \n",
    "\n",
    "The neural network is then trained so as to minimize the difference between the output of the decoder and the input of the encoder.\n",
    "\n",
    "The Variational Auto Encoder is an improved version of the typical Auto Encoder. Instead of outputting a conventional vectorat the Encoder, the latter will output two sets of vectors which are gaussian paramters. The VAE makes use of Variational Inference to optimize towards the solution.\n",
    "\n",
    "### Mathematical Background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam,Adagrad\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "from utils.MiraBest import MiraBest\n",
    "\n",
    "from utils.FRDEEP import FRDEEPF\n",
    "\n",
    "\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network_configurations.neural_net_conf_0_0 as network #change this here to change configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classifier_fr import classification_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_first():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "    trainset = MiraBest(root='./FIRST_data', train=True, download=True, transform=transform)  \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=len(trainset))\n",
    "    \n",
    "    classes = ('FRI', 'FRII') #First class if FR1 and second class is FR2\n",
    "    \n",
    "    array_train= next(iter(trainloader))[0].numpy() # Training Datasets is loaded in numpy array\n",
    "    array_label= next(iter(trainloader))[1].numpy()\n",
    "    \n",
    "    augmented_data=np.zeros((len(array_train)*36,1,100,100))\n",
    "    \n",
    "    augmented_data_label = np.zeros((len(array_train)*36,1))\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for j in range(0,len(array_train)):\n",
    "        image_object=Image.fromarray(array_train[j,0,:,:])\n",
    "        for i in range(0,36):\n",
    "            rotated=image_object.rotate(i*10)\n",
    "            imgarr = np.array(rotated)\n",
    "            temp_img_array=imgarr[25:125,25:125]\n",
    "            augmented_data[count,0,:,:]=temp_img_array\n",
    "            augmented_data_label[count,:]=array_label[j]\n",
    "            count+=1\n",
    "    augmented_data=(augmented_data-np.min(augmented_data))/(np.max(augmented_data)-np.min(augmented_data))\n",
    "    \n",
    "    X=augmented_data\n",
    "    Y=augmented_data_label\n",
    "    \n",
    "    X_random_mix=np.take(X,np.random.RandomState(seed=42).permutation(X.shape[0]),axis=0,out=X)\n",
    "    Y_random_mix=np.take(Y,np.random.RandomState(seed=42).permutation(Y.shape[0]),axis=0,out=Y)\n",
    "    \n",
    "    tensor_x = torch.stack([torch.Tensor(i) for i in X_random_mix])\n",
    "    tensor_y = torch.stack([torch.Tensor(i) for i in Y_random_mix])\n",
    "    \n",
    "    first_augmented_dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y)\n",
    "    \n",
    "    first_dataloader = torch.utils.data.DataLoader(first_augmented_dataset,batch_size=100, shuffle=True) # create your dataloader\n",
    "    \n",
    "    #--------------------------------------Add Section for Test data------------------------------------\n",
    "    \n",
    "    # Cropping of the Testing Images to 100 by 100 pixels\n",
    "    \n",
    "    \n",
    "    testset = MiraBest(root='./FIRST_data', train=False, download=True, transform=transform) \n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=True, num_workers=2, batch_size=len(testset))\n",
    "\n",
    "    array_test= next(iter(testloader))[0].numpy()\n",
    "    \n",
    "    test_labels = next(iter(testloader))[1].numpy()\n",
    "    \n",
    "    test_data_reduced=np.zeros((len(array_test),1,100,100))\n",
    "    test_data_label = np.zeros((len(array_test),1))\n",
    "    \n",
    "    for k in range (0,len(array_test)):\n",
    "        test_data_reduced[k][0][:][:] = array_test[k][0][25:125,25:125]\n",
    "        test_data_label[k,:]=test_labels[k]\n",
    "    \n",
    "    test_data_reduced=(test_data_reduced-np.min(test_data_reduced))/(np.max(test_data_reduced)-np.min(test_data_reduced))\n",
    "    \n",
    "    \n",
    "    \n",
    "    tensor_test = torch.stack([torch.Tensor(i) for i in test_data_reduced])\n",
    "    tensor_test_label = torch.stack([torch.Tensor(i) for i in test_data_label])\n",
    "    \n",
    "    first_augmented_dataset_test = torch.utils.data.TensorDataset(tensor_test,tensor_test_label) # create your datset\n",
    "    \n",
    "    first_dataloader_test = torch.utils.data.DataLoader(first_augmented_dataset_test,batch_size=50, shuffle=True) # create your dataloader\n",
    "    \n",
    "    return first_dataloader,first_dataloader_test\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, x_dim=10000, y_dim=2, h_dim1=500, z_dim=2, use_cuda=True):\n",
    "        super(VAE, self).__init__()\n",
    "    \n",
    "        # create the encoder and decoder networks\n",
    "        # a split in the final layer's size is used for multiple outputs\n",
    "        # and potentially applying separate activation functions on them\n",
    "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
    "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
    "              \n",
    "        self.encoder_z = network.EncoderZ(x_dim, y_dim, h_dim1, z_dim)\n",
    "        \n",
    "        self.decoder = network.Decoder(x_dim, y_dim, h_dim1, z_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "            \n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "        self.output_size = y_dim\n",
    "        \n",
    "        \n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, xs, ys):\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"ss_vae\", self)\n",
    "        batch_size = xs.size(0)\n",
    "\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            # sample the handwriting style from the constant prior distribution\n",
    "            prior_loc = xs.new_zeros([batch_size, self.z_dim])\n",
    "            prior_scale = xs.new_ones([batch_size, self.z_dim])\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "            alpha_prior = xs.new_ones([batch_size, self.output_size]) / (1.0 * self.output_size)\n",
    "            ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha_prior), obs=ys)\n",
    "            \n",
    "            # finally, score the image (x) using the handwriting style (z) and\n",
    "            # the class label y (which digit to write) against the\n",
    "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
    "            # where `decoder` is a neural network\n",
    "            loc = self.decoder.forward([zs, ys])\n",
    "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
    "            \n",
    "    def guide(self, xs, ys):\n",
    "        with pyro.plate(\"data\"):\n",
    "           # if the class label (the digit) is not supervised, sample\n",
    "           # (and score) the digit with the variational distribution\n",
    "           # q(y|x) = categorical(alpha(x))\n",
    "           \n",
    "            #-------------------REMOVED THIS PART FOR THE CLASSIFIER ASSUME ALL DATA ARE LABELLED---------\n",
    "\n",
    "           # sample (and score) the latent handwriting-style with the variational\n",
    "           # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "           loc, scale = self.encoder_z.forward([xs, ys])\n",
    "           pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, xs, ys):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder_z.forward([xs,ys])\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder.forward([zs,ys])\n",
    "        \n",
    "        return loc_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=True):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, y in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        labels_y = torch.tensor(np.zeros((y.shape[0],2)))\n",
    "        y_2=torch.Tensor.cpu(y.reshape(1,y.size()[0])[0]).numpy().astype(int)  \n",
    "        labels_y=np.eye(2)[y_2]\n",
    "        labels_y = torch.from_numpy(labels_y)   \n",
    "         \n",
    "        epoch_loss += svi.step(x.reshape(-1,10000),labels_y.cuda().float())\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=True):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x,y in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x) #Data entry point <---------------------------------Data Entry Point\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_sample_plotter(epoch):\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        z_fr1 = z_fr2 = torch.randn(100, 2)\n",
    "        labels_y1 = torch.tensor(np.zeros((100,2)))\n",
    "        labels_y2 = torch.tensor(np.zeros((100,2)))\n",
    "        for i in range (0,10):\n",
    "            for j in range (0,10):\n",
    "                z_fr1[count,0] = z_fr2[count,0] = np.random.uniform(-1,1)\n",
    "                z_fr1[count,1] = z_fr2[count,1] = np.random.uniform(-1,1)\n",
    "                labels_y1[count,0] = 1\n",
    "                labels_y2[count,1] = 1\n",
    "                count = count +1 \n",
    "        \n",
    "        sample1 = vae.decoder([z_fr1.cuda(),labels_y1.cuda().float()])\n",
    "    \n",
    "        save_image(sample1.view(100, 1, 100, 100), 'fr1_sample_2_z_space_' +str(epoch)+'.png',nrow=10)\n",
    "    \n",
    "        sample2 = vae.decoder([z_fr2.cuda(),labels_y2.cuda().float()])\n",
    "\n",
    "        save_image(sample2.view(100, 1, 100, 100), 'fr2_sample_2_z_space_' +str(epoch)+'.png',nrow=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(epoch):\n",
    "    #print(\"loading model from ...\")\n",
    "    vae.load_state_dict(torch.load('/raid/scratch/davidb/1_DEVELOPMENT/VAE_FIRST/models/file_conf00x3_semi_supervised_vae_FRDEEP_epoch_'+str(epoch)))\n",
    "   # print(\"loading optimizer states from ...\")\n",
    "    optimizer.load('/raid/scratch/davidb/1_DEVELOPMENT/VAE_FIRST/models/file_conf00x3_semi_supervised_vae_FRDEEP_epoch_'+str(epoch)+'_opt')\n",
    "   # print(\"done loading model and optimizer states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch):\n",
    "    print(\"saving model to ...\")\n",
    "    torch.save(vae.state_dict(), '/raid/scratch/davidb/1_DEVELOPMENT/VAE_FIRST/models/file_conf00x3_semi_supervised_vae_FRDEEP_epoch_'+str(epoch))\n",
    "    print(\"saving optimizer states...\")\n",
    "    optimizer.save('/raid/scratch/davidb/1_DEVELOPMENT/VAE_FIRST/models/file_conf00x3_semi_supervised_vae_FRDEEP_epoch_'+str(epoch)+'_opt')\n",
    "    print(\"done saving model and optimizer checkpoints to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = True\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 20000\n",
    "TEST_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_array=np.zeros((1,2))\n",
    "\n",
    "results_array_temp=np.zeros((1,2))\n",
    "\n",
    "results_array_test=np.zeros((1,2))\n",
    "\n",
    "results_array_temp_test=np.zeros((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader = dataloader_first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the VAE\n",
    "pyro.clear_param_store()\n",
    "\n",
    "net = classification_procedure()\n",
    "\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adagrad_params = {\"lr\": 0.001}\n",
    "optimizer = Adagrad(adagrad_params)\n",
    "\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range (0,2000):\n",
    " \n",
    "    \n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    \n",
    "    \n",
    "    train_loss = 0.\n",
    "    for x, y in train_loader:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "            # compute ELBO estimate and accumulate loss\n",
    "        labels_y = torch.tensor(np.zeros((y.shape[0],2)))\n",
    "        y_2=torch.Tensor.cpu(y.reshape(1,y.size()[0])[0]).numpy().astype(int)  \n",
    "        labels_y=np.eye(2)[y_2]\n",
    "        labels_y = torch.from_numpy(labels_y)\n",
    "        \n",
    "        train_loss += svi.evaluate_loss(x.reshape(-1,10000),labels_y.cuda().float()) \n",
    "            \n",
    "            \n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = train_loss / normalizer_train\n",
    "        \n",
    "    \n",
    "    \n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_loss = 0.\n",
    "        # compute the loss over the entire test set\n",
    "    for x_test,y_test in test_loader:\n",
    "\n",
    "            x_test = x_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "            # compute ELBO estimate and accumulate loss\n",
    "            labels_y_test = torch.tensor(np.zeros((y_test.shape[0],2)))\n",
    "            y_test_2=torch.Tensor.cpu(y_test.reshape(1,y_test.size()[0])[0]).numpy().astype(int)  \n",
    "            labels_y_test=np.eye(2)[y_test_2]\n",
    "            labels_y_test = torch.from_numpy(labels_y_test)\n",
    "        \n",
    "            test_loss += svi.evaluate_loss(x_test.reshape(-1,10000),labels_y_test.cuda().float()) \n",
    "            \n",
    "            \n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    \n",
    "    z_fr1 = z_fr2 = torch.FloatTensor(100, 2).uniform_(-2, 2)\n",
    "    labels_y1 = torch.tensor(np.zeros((100,2)))\n",
    "    labels_y2 = torch.tensor(np.zeros((100,2)))\n",
    "        \n",
    "    labels_y1[:,1] = 0\n",
    "    labels_y2[:,1] = 0\n",
    "\n",
    "    labels_y1[:,0] = 0\n",
    "    labels_y2[:,0] = 0\n",
    "\n",
    "    labels_y1[:,1] = 2\n",
    "    labels_y2[:,0] = 2\n",
    "\n",
    "    sample_fr1 = vae.decoder([z_fr1.cuda(),labels_y1.cuda().float()])\n",
    "    img1=sample_fr1.reshape(100,100,100).cpu().detach().numpy()\n",
    " \n",
    "\n",
    "    sample_fr2 = vae.decoder([z_fr2.cuda(),labels_y2.cuda().float()])\n",
    "    img2=sample_fr2.reshape(100,100,100).cpu().detach().numpy()\n",
    "\n",
    "    classification_results = np.zeros((1,100))\n",
    "    \n",
    "    array_fr1 = np.zeros(100)\n",
    "    array_fr2 = np.zeros(100)\n",
    "    for i in range (0,100):\n",
    "        img_tensor = torch.tensor(np.zeros((1,1,150,150)))\n",
    "        img_tensor[0,0,25:125,25:125]=sample_fr2[i].reshape(100,100)\n",
    "        outputs = net(img_tensor.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        array_fr2[i]= float(predicted[0].cpu().detach().numpy())\n",
    "\n",
    "        img_tensor = torch.tensor(np.zeros((1,1,150,150)))\n",
    "        img_tensor[0,0,25:125,25:125]=sample_fr1[i].reshape(100,100)\n",
    "        outputs = net(img_tensor.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "        array_fr1[i]= float(predicted[0].cpu().detach().numpy())   \n",
    "    \n",
    "    print('Train Loss: '+str(total_epoch_loss_train)+' Test Loss:'+str(total_epoch_loss_test)+' VAE Efficiency:'+str((collections.Counter(array_fr1)[1]+collections.Counter(array_fr2)[0])/200))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_fr1 = z_fr2 = torch.FloatTensor(100, 2).uniform_(-2, 2)\n",
    "labels_y1 = torch.tensor(np.zeros((100,2)))\n",
    "labels_y2 = torch.tensor(np.zeros((100,2)))\n",
    "        \n",
    "labels_y1[:,1] = 0\n",
    "labels_y2[:,1] = 0\n",
    "\n",
    "labels_y1[:,0] = 0\n",
    "labels_y2[:,0] = 0\n",
    "\n",
    "labels_y1[:,1] = 2\n",
    "labels_y2[:,0] = 2\n",
    "\n",
    "sample_fr1 = vae.decoder([z_fr1.cuda(),labels_y1.cuda().float()])\n",
    "img1=sample_fr1.reshape(100,100,100).cpu().detach().numpy()\n",
    " \n",
    "\n",
    "sample_fr2 = vae.decoder([z_fr2.cuda(),labels_y2.cuda().float()])\n",
    "img2=sample_fr2.reshape(100,100,100).cpu().detach().numpy()\n",
    "\n",
    "classification_results = np.zeros((1,100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1.imshow(sample_fr1[i].reshape(100,100).cpu().detach().numpy())\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.imshow(img2[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(array_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 85\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(img1[num])\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(img2[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.tensor(np.zeros((1,1,150,150)))\n",
    "img_tensor[0,0,25:125,25:125]==sample_fr2[i].reshape(100,100)\n",
    "outputs = net(img_tensor.float())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(img1[i])\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(img2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1.imshow(sample_fr1[i].reshape(100,100).cpu().detach().numpy())\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.imshow(img2[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
