{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classification_function import classfication_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam,Adagrad\n",
    "import pyro.poutine as poutine\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from PIL import Image # Module for image rotation (making use of PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.MiraBest import MiraBest\n",
    "from utils.MiraBest_full import MiraBest_full\n",
    "from utils.FRDEEP import FRDEEPF\n",
    "from utils.data_downloader import dataloader_first_noisy\n",
    "from utils.data_downloader import dataloader_first_FRDEEP\n",
    "\n",
    "import network_configurations.neural_net_conf_0_2_dropout as network #change this here to change configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stating Training of CNN\n",
      "Files already downloaded and verified\n",
      "stattng training\n",
      "Epoch: 0, Loss: 2.1898093223571777, Train Accuracy: 0.5300324675324676\n",
      "Epoch: 0, Loss: 0.7935073001818224, Validation Accuracy: 0.41825139379346526\n",
      "Final validation error:  58.17486062065347\n",
      "Accuracy of the network on the test images: 48 %\n",
      "Accuracy of   FRI : 100 %\n",
      "Accuracy of  FRII :  7 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 1, Loss: 1.1200904846191406, Train Accuracy: 0.557224025974026\n",
      "Epoch: 1, Loss: 0.6830770682978939, Validation Accuracy: 0.517741190226047\n",
      "Final validation error:  48.2258809773953\n",
      "Accuracy of the network on the test images: 58 %\n",
      "Accuracy of   FRI : 100 %\n",
      "Accuracy of  FRII : 25 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 2, Loss: 0.955730676651001, Train Accuracy: 0.5831574675324676\n",
      "Epoch: 2, Loss: 0.6542029321967782, Validation Accuracy: 0.5634044561293218\n",
      "Final validation error:  43.65955438706782\n",
      "Accuracy of the network on the test images: 70 %\n",
      "Accuracy of   FRI : 100 %\n",
      "Accuracy of  FRII : 46 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 3, Loss: 1.1597599983215332, Train Accuracy: 0.6066964285714286\n",
      "Epoch: 3, Loss: 0.6227919434572196, Validation Accuracy: 0.6360621559155452\n",
      "Final validation error:  36.393784408445484\n",
      "Accuracy of the network on the test images: 78 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 64 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 4, Loss: 0.4087759554386139, Train Accuracy: 0.6233766233766234\n",
      "Epoch: 4, Loss: 0.6067528447160473, Validation Accuracy: 0.6642393367631095\n",
      "Final validation error:  33.57606632368905\n",
      "Accuracy of the network on the test images: 82 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 71 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 5, Loss: 0.7141872644424438, Train Accuracy: 0.6423295454545455\n",
      "Epoch: 5, Loss: 0.5831873820973681, Validation Accuracy: 0.7087894295717214\n",
      "Final validation error:  29.121057042827857\n",
      "Accuracy of the network on the test images: 84 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 75 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 6, Loss: 0.7739403247833252, Train Accuracy: 0.6612418831168831\n",
      "Epoch: 6, Loss: 0.5687107230935778, Validation Accuracy: 0.7181818239100568\n",
      "Final validation error:  28.18181760899432\n",
      "Accuracy of the network on the test images: 88 %\n",
      "Accuracy of   FRI : 95 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 7, Loss: 1.0401471853256226, Train Accuracy: 0.6726866883116883\n",
      "Epoch: 7, Loss: 0.5609119569713419, Validation Accuracy: 0.7369434197227677\n",
      "Final validation error:  26.305658027723233\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 8, Loss: 0.4951328635215759, Train Accuracy: 0.6911525974025974\n",
      "Epoch: 8, Loss: 0.5519962272473744, Validation Accuracy: 0.7362476859773909\n",
      "Final validation error:  26.375231402260912\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 9, Loss: 0.9313246607780457, Train Accuracy: 0.7003246753246753\n",
      "Epoch: 9, Loss: 0.5446355662175587, Validation Accuracy: 0.7456400800060916\n",
      "Final validation error:  25.43599199939084\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 10, Loss: 0.5179267525672913, Train Accuracy: 0.7123782467532468\n",
      "Epoch: 10, Loss: 0.5335221644345816, Validation Accuracy: 0.7454545510279668\n",
      "Final validation error:  25.454544897203323\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 11, Loss: 0.4690881371498108, Train Accuracy: 0.7206574675324675\n",
      "Epoch: 11, Loss: 0.5311057238416238, Validation Accuracy: 0.7456632703929752\n",
      "Final validation error:  25.43367296070248\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 12, Loss: 0.28798097372055054, Train Accuracy: 0.7269074675324675\n",
      "Epoch: 12, Loss: 0.5224715564545099, Validation Accuracy: 0.7454545505635151\n",
      "Final validation error:  25.454544943648493\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 13, Loss: 0.25290971994400024, Train Accuracy: 0.7393668831168831\n",
      "Epoch: 13, Loss: 0.5222759187995614, Validation Accuracy: 0.7448747727778051\n",
      "Final validation error:  25.512522722219487\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 14, Loss: 0.5050863027572632, Train Accuracy: 0.7487824675324676\n",
      "Epoch: 14, Loss: 0.513942625383278, Validation Accuracy: 0.7545454598092414\n",
      "Final validation error:  24.545454019075862\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 15, Loss: 0.4366714060306549, Train Accuracy: 0.744237012987013\n",
      "Epoch: 15, Loss: 0.5081002876743094, Validation Accuracy: 0.7816558495744482\n",
      "Final validation error:  21.83441504255518\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 16, Loss: 0.5702514052391052, Train Accuracy: 0.760349025974026\n",
      "Epoch: 16, Loss: 0.5065734372123495, Validation Accuracy: 0.7811224548847644\n",
      "Final validation error:  21.88775451152356\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 17, Loss: 0.476616233587265, Train Accuracy: 0.7581980519480519\n",
      "Epoch: 17, Loss: 0.5031188610312226, Validation Accuracy: 0.7816094680265947\n",
      "Final validation error:  21.83905319734053\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 18, Loss: 0.5432664155960083, Train Accuracy: 0.7600649350649351\n",
      "Epoch: 18, Loss: 0.49605175539270624, Validation Accuracy: 0.7815398948533194\n",
      "Final validation error:  21.84601051466806\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 19, Loss: 0.6395702362060547, Train Accuracy: 0.7730113636363637\n",
      "Epoch: 19, Loss: 0.4939895969319653, Validation Accuracy: 0.7819573345122399\n",
      "Final validation error:  21.804266548776006\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 20, Loss: 0.7304407358169556, Train Accuracy: 0.7779220779220779\n",
      "Epoch: 20, Loss: 0.49421228385203847, Validation Accuracy: 0.7817949971595368\n",
      "Final validation error:  21.820500284046318\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 21, Loss: 0.5904549956321716, Train Accuracy: 0.78125\n",
      "Epoch: 21, Loss: 0.4852322687769865, Validation Accuracy: 0.7816094678717774\n",
      "Final validation error:  21.839053212822257\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.3111999034881592, Train Accuracy: 0.7810876623376624\n",
      "Epoch: 22, Loss: 0.48756554993716156, Validation Accuracy: 0.7815630853950203\n",
      "Final validation error:  21.843691460497972\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 23, Loss: 0.17002274096012115, Train Accuracy: 0.7836444805194805\n",
      "Epoch: 23, Loss: 0.4858942299307167, Validation Accuracy: 0.7731447185788836\n",
      "Final validation error:  22.685528142111643\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 24, Loss: 0.7708264589309692, Train Accuracy: 0.7868100649350649\n",
      "Epoch: 24, Loss: 0.48242419725888736, Validation Accuracy: 0.7818413787073903\n",
      "Final validation error:  21.815862129260964\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 25, Loss: 0.14798936247825623, Train Accuracy: 0.7952516233766234\n",
      "Epoch: 25, Loss: 0.4790401252639758, Validation Accuracy: 0.7817022323608398\n",
      "Final validation error:  21.82977676391602\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 26, Loss: 0.5669431090354919, Train Accuracy: 0.794237012987013\n",
      "Epoch: 26, Loss: 0.47313728214471373, Validation Accuracy: 0.7911410079373942\n",
      "Final validation error:  20.885899206260582\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 27, Loss: 0.4585776627063751, Train Accuracy: 0.7990665584415585\n",
      "Epoch: 27, Loss: 0.47434840473261747, Validation Accuracy: 0.7913729190826416\n",
      "Final validation error:  20.862708091735836\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 28, Loss: 0.31148386001586914, Train Accuracy: 0.7982548701298702\n",
      "Epoch: 28, Loss: 0.47416356302701035, Validation Accuracy: 0.7909090971017813\n",
      "Final validation error:  20.909090289821876\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n",
      "Epoch: 29, Loss: 0.21486736834049225, Train Accuracy: 0.8042207792207792\n",
      "Epoch: 29, Loss: 0.47257924583051114, Validation Accuracy: 0.7913033460641836\n",
      "Final validation error:  20.869665393581638\n",
      "Accuracy of the network on the test images: 86 %\n",
      "Accuracy of   FRI : 90 %\n",
      "Accuracy of  FRII : 82 %\n",
      "---------------------------------------------------------------------\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "classification_model = classfication_procedure(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "     #    transforms.CenterCrop(28),\n",
    "    transforms.RandomRotation(0.,360.),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))])\n",
    "trainset = FRDEEPF(root='./FIRST_data', train=True, download=True, transform=transform)  \n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "\t# calculate p(y)\n",
    "\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "\t# kl divergence for each image\n",
    "\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\t# sum over classes\n",
    "\tsum_kl_d = kl_d.sum(axis=1)\n",
    "\t# average over images\n",
    "\tavg_kl_d = mean(sum_kl_d)\n",
    "\t# undo the logs\n",
    "\tis_score = exp(avg_kl_d)\n",
    "\treturn is_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c3f0be78e3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minception_score_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnoise_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0marray_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "inception_score_noise = []\n",
    "noise_value = []\n",
    "for alpha in range (0.0,1.0,0.05):\n",
    "    noise=np.random.random((500,1,150,150))*alpha\n",
    "    array_noise = torch.from_numpy(noise).float().to(\"cpu\")\n",
    "    x_data=x[0]+array_noise\n",
    "    valid_pred = classification_model(x_data.cuda())\n",
    "    m = nn.Softmax(dim=1)\n",
    "    values=m(valid_pred).cpu().detach().numpy()\n",
    "    score = calculate_inception_score(values)\n",
    "    noise_value.append(noise)\n",
    "    inception_score_noise.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cropping_score(edge_size,x):\n",
    "\n",
    "inception_score = []\n",
    "edge_value = []\n",
    "for i in range(0,75,1):\n",
    "    fullsize_image = np.zeros((500,1,150,150))\n",
    "    edge = i\n",
    "    for i in range (0,500):\n",
    "        x_tocrp = x[0][i,0,:,:].cpu().detach().numpy()\n",
    "        fullsize_image[i,0,edge:150-edge,edge:150-edge]=x_tocrp[edge:150-edge,edge:150-edge]\n",
    "    image_to_test = torch.from_numpy(fullsize_image).float().to(\"cuda:0\")\n",
    "\n",
    "    valid_pred = classification_model(image_to_test)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    values=m(valid_pred).cpu().detach().numpy()\n",
    "    score = calculate_inception_score(values)\n",
    "    inception_score.append(score)\n",
    "    edge_value.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3892423,\n",
       " 1.3887277,\n",
       " 1.3868738,\n",
       " 1.3840255,\n",
       " 1.3811108,\n",
       " 1.3772914,\n",
       " 1.3747144,\n",
       " 1.3722751,\n",
       " 1.3677453,\n",
       " 1.3638283,\n",
       " 1.3612721,\n",
       " 1.3539107,\n",
       " 1.3485335,\n",
       " 1.3428478,\n",
       " 1.3359785,\n",
       " 1.3314878,\n",
       " 1.325557,\n",
       " 1.3190933,\n",
       " 1.3115635,\n",
       " 1.3048303,\n",
       " 1.2978019,\n",
       " 1.2889397,\n",
       " 1.2790467,\n",
       " 1.2702991,\n",
       " 1.2604904,\n",
       " 1.2494091,\n",
       " 1.2404444,\n",
       " 1.2249676,\n",
       " 1.213203,\n",
       " 1.2031481,\n",
       " 1.1939538,\n",
       " 1.1817819,\n",
       " 1.169705,\n",
       " 1.1647525,\n",
       " 1.1587654,\n",
       " 1.1472654,\n",
       " 1.1376361,\n",
       " 1.1299292,\n",
       " 1.1232424,\n",
       " 1.1129118,\n",
       " 1.106492,\n",
       " 1.0975602,\n",
       " 1.093135,\n",
       " 1.0848924,\n",
       " 1.080625,\n",
       " 1.0746707,\n",
       " 1.0713314,\n",
       " 1.0689217,\n",
       " 1.066286,\n",
       " 1.0625333,\n",
       " 1.0607952,\n",
       " 1.0569121,\n",
       " 1.0566458,\n",
       " 1.0548253,\n",
       " 1.0534524,\n",
       " 1.0512549,\n",
       " 1.0511403,\n",
       " 1.0500991,\n",
       " 1.0508416,\n",
       " 1.0512846,\n",
       " 1.0510651,\n",
       " 1.0507002,\n",
       " 1.049683,\n",
       " 1.0483646,\n",
       " 1.047116,\n",
       " 1.051159,\n",
       " 1.0536503,\n",
       " 1.0586516,\n",
       " 1.0602344,\n",
       " 1.0694704,\n",
       " 1.0801605,\n",
       " 1.0851156,\n",
       " 1.1054928,\n",
       " 1.097591,\n",
       " 1.1159741]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2511686a58>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(edge_value,inception_score,'+-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_yx=asarray([[0.33, 0.33, 0.33],[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims,asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_y = expand_dims(p_yx.mean(axis=0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.665, 0.665, 0.665]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
